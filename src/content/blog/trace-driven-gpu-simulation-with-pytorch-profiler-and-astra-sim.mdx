---
title: Trace-Driven Simulation in Astra w/ PyTorch Profiler + Hollistic Trace Analysis
description: Analying performance traces with Astra-Sim in a trace-driven manner.
heroImage: hero.png
pubDate: April 28 2024
display: false
unlisted: true
---

import { Image } from "astro:assets";
import chakra_central from "../../blog/trace-driven-gpu-simulation-with-pytorch-profiler-and-astra-sim/chakra_central.png";
import tpu_correlation from "../../blog/trace-driven-gpu-simulation-with-pytorch-profiler-and-astra-sim/tpu_correlation.png";

{/* Talk about what simulation is and why it is important to hardware design */}

In this tutorial, we will be:

- Loading a PyTorch model ([Microsoft's Phi](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)) from Hugging Face
- Running inference on the model using a Shakespeare dataset
- Collecting traces using PyTorch Profiler
- Converting PyTorch profiler's execution traces to Chakra Execution Traces
- Building Astra-Sim
- Running an Astra-Sim simulation

{/* Talk about simulation moving from hardware to network design */}

## Hardware and Network Simulators

Simulators are well-established, good proxies for real-world systems. Hardware and network simulators provide timings and output characteristics very similar to real-world systems. This is useful because new hardware and network designs may be tested in simulation and have real-world impact.

<figure>
  <Image
    src={tpu_correlation}
    alt="Correlation in performance between Astra-Sim and a real-world environment"
  />
  <figcaption>
    Correlating performance between Astra-Sim and a real-world experiment on a
    Tensor Processing Unit (TPU)
  </figcaption>
</figure>

## Getting Started

To get started with simulation, we will begin by creating a contrived example of measuring performance on a standard Hugging-Face model. From this model, fine-tuning will take place and traces will be collected using PyTorch Profiler, analyzed using Holistic Trace Analysis, converted to Chakra Execution Traces and simulated using Astra-Sim.

### Getting PyTorch Setup

First, install [PyTorch](https://pytorch.org/get-started/locally/) and [TorchVision](https://pytorch.org/vision/stable/index.html) using pip.

```bash
pip install torch torchvision
```

Next, we may import torch and setup cuda as a default device.

```python
import torch
import torch.nn as nn

torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

### Data Loading

To load the MNIST data, we will use a DataLoader from PyTorch. This will allow us to load the data in batches and shuffle the data for training and testing.

```python
from torchvision import datasets
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader

# Loading the MNIST dataset
train_data = datasets.MNIST(root = 'data', train = True, transform = ToTensor(), download=True)

# Creating data loade
train_data = DataLoader(train_data, batch_size=64, num_workers=4, pin_memory=True)
```

### Defining a Model

We will define a simple CNN model for classifying the MNIST dataset. For this contrived example, the modle used will only be for demonstration purposes.

```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(
                in_channels=1,
                out_channels=40,
                kernel_size=5,
                stride=1,
                padding=2,
            ),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(40, 32, 5, 1, 2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        # fully connected layer, output 10 classes
        self.out = nn.Linear(32 * 7 * 7, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)
        x = x.view(x.size(0), -1)
        output = self.out(x)
        return output, x    # return x for visualization

cnn = CNN()
cnn.cuda()
```

## Defining an Epoch Training Function

To train the mode, we will first define a basic function which takes a batch of data from the data loader and uses it to train the model.

```python
loss_func = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)

def train(batch_data):
    """
    Very basic training loop for a CNN model
    """
    # data movement
    images, labels = batch_data
    images, labels = images.cuda(), labels.cuda()

    # Forward pass
    output = cnn(images)[0]
    loss = loss_func(output, labels)

    # clear gradients for this training step
    optimizer.zero_grad()

    # backgpropagation, compute gradients
    loss.backward()

    # apply gradients
    optimizer.step()
```

Now, all we have to do is run the training loop with the profiler setup to cllect our traces.

### Trace Collection

After setting up the model, we can collect traces with PyTorch Profiler. The PyTorch Profiler is a context manager that allows you to collect traces within your model's training loop. For use in trace analysis, you must use a `tensorboard_trace_handler` to save the traces to disk with both CPU and GPU activity.

```python
from torch.profiler import profile, schedule, tensorboard_trace_handler, ProfilerActivity

tracing_schedule = schedule(skip_first=5, wait=5, warmup=2, active=2, repeat=1)
trace_handler = tensorboard_trace_handler(dir_name="traces", use_gzip=True)

EPOCHS = 1 # number of epochs to train 

with profile(
  activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA],
  schedule = tracing_schedule,
  on_trace_ready = trace_handler,
  profile_memory = True,
  record_shapes = True,
  with_stack = True
) as prof:
  for epoch in range(EPOCHS):
    for step, batch_data in enumerate(train_data):
        train(batch_data)
        prof.step()
```

Following this, a `traces` directory will be created which contains compressed json files of CPU and GPU activity. Theses traces are the input to both: Holistic Trace Analysis and Astra-Sim.

### Converting to Chakra Execution Traces (ET)

[Charka](https://engineering.fb.com/2023/09/07/networking-traffic/chakra-execution-traces-benchmarking-network-performance-optimization/) is a library produced by Meta AI research with the goal of providing a standardized format for simulators, analyzers and collectors to use for traces.

<figure>
  <Image src={chakra_central} alt="Chakra execution traces being central" />
  <figcaption>
    Chakra Execution Traes Providing a Centralized Data Format
  </figcaption>
</figure>

Using Charka consists of converting PyTorch Execution Traces produced earlier into Chakra using Chakra's execution trace converter.

First, begin by installing Chakra:

```bash
git clone https://github.com/mlcommons/chakra/
cd chakra
pip install -e .
cd -
```

Then, use a python script for converting the scripts:

```python
from chakra.et_converter.pytorch2chakra_converter import PyTorch2ChakraConverter
import logging

for rank, trace in files.items():
  converter = PyTorch2ChakraConverter(trace, trace, logging.getLogger(__file__))
  converter.convert() # not too sure about this, it makes the simulation more often
```

### Setting Up Astra-Sim

Astra Sim is a trace driven simulator designed for both hardware and network simulation. To get started, we will build Astra-Sim from source in a Docker container.

```bash
git clone --recurse-submodules git@github.com:astra-sim/astra-sim.git
cd astra-sim
```

> Note: this uses a rsa key, rather than https which is required because each submodule also has submodules which use RSA keys

After cloning, we can build the Docker container used to build and run the simulation. If you do not have Docker installed, please see the [Get Docker](https://docs.docker.com/get-docker/).

```bash
# sudo docker run -it astra-sim # (interactive mode)
sudo docker build -t astra-sim .
sudo docker run -dt --name astra-sim astra-sim
sudo docker exec astra-sim ./build/astra_analytical/build.sh
```

After buiding the container, you should see the following output indicating a successful build:

```console
[ 98%] Building CXX object AstraSim_Analytical/CMakeFiles/AstraSim_Analytical_Congestion_Aware.dir/congestion_aware/main.cc.o
[ 99%] Linking CXX executable ../bin/AstraSim_Analytical_Congestion_Unaware
[100%] Linking CXX executable ../bin/AstraSim_Analytical_Congestion_Aware
[100%] Built target AstraSim_Analytical_Congestion_Unaware
[100%] Built target AstraSim_Analytical_Congestion_Aware
```

### Loading Astra-Sim Execution Traces

After Astra-Sim has been built, we can load the execution traces in Astra-Sim with a basic docker copy.

```bash
sudo docker cp traces astra-sim:/app/astra-sim/inputs/workload/ASTRA-sim-2.0
```

Now, we have all our data in place to run Astra-Sim.

### Running Astra-Sim

After the binary is built, you can run a simulation in Astra-Sim using the following command:

```bash
BINARY=./build/astra_analytical/build/bin/AstraSim_Analytical_Congestion_Unaware
WORKLOAD_CONFIG=./inputs/workload/ASTRA-sim-2.0/traces # chakra et traces
SYSTEM_CONFIG=./inputs/system/Switch.json
NETWORK_CONFIG=./inputs/network/analytical/Switch.yml
REMOTE_MEMORY_CONFIG=./inputs/remote_memory/analytical/no_memory_expansion.json

sudo docker exec astra-sim ${BINARY} \
  --workload-configuration=${WORKLOAD_CONFIG} \
  --system-configuration=${SYSTEM_CONFIG} \
  --network-configuration=${NETWORK_CONFIG} \
  --remote-memory-configuration=${REMOTE_MEMORY_CONFIG}
```

Finally, you will get an output like the following indicating the simulation has terminated.

```console
sys[62] finished, 6749042 cycles
sys[61] finished, 6749042 cycles
...
sys[0] finished, 6749042 cycles
sys[63] finished, 6749042 cycles
```

For more details about configuring Astra-Sim, please see the [Run Astra-Sim Documenation](https://astra-sim.github.io/astra-sim-docs/getting-started/running-astra-sim.html).

## Summary

In this tutorial, we have defined a simple CNN model for classifying the MNIST dataset. Model training was analyized with PyTorch Profiler and traces were collected. Traces were then able to be: analyzed and converted into Chakra executions traces. Finally, Astra-Sim was then used to simulate how these traces would execute on a network.

If you want to play around with this yourself, you may use [Google Collab to view this entire process as a notebook](https://colab.research.google.com/drive/1t0IgZ8eZ5N7zwZci-jOMXycv78isUWS2).
